{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from nni.algorithms.compression.v2.pytorch.pruning import LinearPruner\n",
    "from nni.compression.pytorch import TorchEvaluator\n",
    "import nni"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris[\"data\"]\n",
    "X = Variable(torch.from_numpy(StandardScaler().fit_transform(X))).float()\n",
    "y = iris[\"target\"]\n",
    "y = Variable(torch.from_numpy(y)).long()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 32),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(32, 3),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    "    loss_start = loss_fn(y_pred, y)\n",
    "\n",
    "for i in range(1000):\n",
    "    y_pred = model(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    "    loss_end = loss_fn(y_pred, y)\n",
    "\n",
    "assert (loss_start-loss_end) >= 0.01, f\"{(loss_start-loss_end)}\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-20 16:11:24] \u001B[33mWARNING: The old API ...finetuner,speedup,dummy_input,evaluator,pruning_params will be deprecated after NNI v3.0,please using the new one ...evaluator,speedup,pruning_params\u001B[0m\n",
      "[2022-11-20 16:11:24] \u001B[33mWARNING: This compressor is not set model and config_list, waiting for reset() or pass this to scheduler.\u001B[0m\n",
      "[2022-11-20 16:11:24] \u001B[33mWARNING: The old API ...finetuner,speedup,dummy_input,evaluator,reset_weight will be deprecated after NNI v3.0,please using the new one ...evaluator,speedup,reset_weight\u001B[0m\n",
      "[2022-11-20 16:11:24] \u001B[32msimulated prune 0 remain/total: 32/32\u001B[0m\n",
      "[2022-11-20 16:11:24] \u001B[32msimulated prune 2 remain/total: 3/3\u001B[0m\n",
      "[2022-11-20 16:11:24] \u001B[32msimulated prune 0 remain/total: 32/32\u001B[0m\n",
      "[2022-11-20 16:11:24] \u001B[32msimulated prune 2 remain/total: 3/3\u001B[0m\n",
      "[2022-11-20 16:11:25] \u001B[32msimulated prune 0 remain/total: 31/32\u001B[0m\n",
      "[2022-11-20 16:11:25] \u001B[32msimulated prune 2 remain/total: 3/3\u001B[0m\n",
      "[2022-11-20 16:11:25] \u001B[32msimulated prune 0 remain/total: 31/32\u001B[0m\n",
      "[2022-11-20 16:11:25] \u001B[32msimulated prune 2 remain/total: 3/3\u001B[0m\n",
      "[2022-11-20 16:11:25] \u001B[32msimulated prune 0 remain/total: 31/32\u001B[0m\n",
      "[2022-11-20 16:11:25] \u001B[32msimulated prune 2 remain/total: 3/3\u001B[0m\n",
      "[2022-11-20 16:11:25] \u001B[32msimulated prune 0 remain/total: 31/32\u001B[0m\n",
      "[2022-11-20 16:11:25] \u001B[32msimulated prune 2 remain/total: 3/3\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "config_list = [{\n",
    "    'sparsity_per_layer': 0.5,\n",
    "    'op_types': ['Linear']\n",
    "}]\n",
    "itpruner = LinearPruner(model, config_list, \"level\", log_dir=\"./.nni_log\", total_iteration=5)\n",
    "itpruner.compress()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "iteration, model, model_masks, *_ = itpruner.get_best_result()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from actuallysparse import converter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# todo: zintegrować jako część konwertera\n",
    "sparse_model = nn.Sequential(\n",
    "    converter.convert(model[0], \"coo\", model_masks[\"0\"][\"weight\"]),\n",
    "    model[1],\n",
    "    converter.convert(model[2], \"coo\", model_masks[\"2\"][\"weight\"]),\n",
    "    model[3]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.2866e-01, 7.7130e-01, 4.2970e-05],\n        [1.2582e-01, 8.7412e-01, 6.1340e-05],\n        [2.0059e-01, 7.9935e-01, 5.2136e-05],\n        [1.7629e-01, 8.2365e-01, 6.1827e-05],\n        [2.6519e-01, 7.3477e-01, 4.1297e-05],\n        [2.8343e-01, 7.1651e-01, 5.4384e-05],\n        [2.6471e-01, 7.3524e-01, 5.6522e-05],\n        [2.1195e-01, 7.8800e-01, 4.7899e-05],\n        [1.4546e-01, 8.5447e-01, 7.1931e-05],\n        [1.4797e-01, 8.5198e-01, 4.9855e-05],\n        [2.3590e-01, 7.6406e-01, 3.9550e-05],\n        [2.3170e-01, 7.6825e-01, 5.1242e-05],\n        [1.3683e-01, 8.6312e-01, 5.2247e-05],\n        [1.9759e-01, 8.0236e-01, 5.0313e-05],\n        [2.5698e-01, 7.4299e-01, 3.0701e-05],\n        [3.4152e-01, 6.5844e-01, 4.1310e-05],\n        [2.9567e-01, 7.0429e-01, 4.4965e-05],\n        [2.3083e-01, 7.6912e-01, 5.0398e-05],\n        [2.2018e-01, 7.7977e-01, 4.6961e-05],\n        [2.9955e-01, 7.0040e-01, 4.5136e-05],\n        [1.6159e-01, 8.3836e-01, 4.9783e-05],\n        [2.8102e-01, 7.1893e-01, 5.5605e-05],\n        [3.2889e-01, 6.7107e-01, 3.6655e-05],\n        [1.6715e-01, 8.3275e-01, 9.8849e-05],\n        [2.1994e-01, 7.8000e-01, 5.8974e-05],\n        [1.1177e-01, 8.8816e-01, 6.5710e-05],\n        [2.0998e-01, 7.8995e-01, 7.1431e-05],\n        [2.1340e-01, 7.8656e-01, 4.4293e-05],\n        [1.9237e-01, 8.0758e-01, 4.4872e-05],\n        [1.8916e-01, 8.1078e-01, 5.9159e-05],\n        [1.5257e-01, 8.4737e-01, 6.2710e-05],\n        [1.6814e-01, 8.3180e-01, 6.5081e-05],\n        [3.2921e-01, 6.7076e-01, 3.1530e-05],\n        [3.2094e-01, 6.7903e-01, 3.2484e-05],\n        [1.4638e-01, 8.5356e-01, 5.9210e-05],\n        [1.7108e-01, 8.2888e-01, 4.8239e-05],\n        [1.8528e-01, 8.1468e-01, 3.9541e-05],\n        [2.7355e-01, 7.2642e-01, 3.6321e-05],\n        [1.7678e-01, 8.2315e-01, 6.3434e-05],\n        [2.0041e-01, 7.9954e-01, 4.7327e-05],\n        [2.4665e-01, 7.5331e-01, 4.8777e-05],\n        [3.4394e-02, 9.6546e-01, 1.4715e-04],\n        [2.3496e-01, 7.6499e-01, 5.4134e-05],\n        [2.3967e-01, 7.6023e-01, 9.9844e-05],\n        [2.9088e-01, 7.0906e-01, 6.4797e-05],\n        [1.3205e-01, 8.6788e-01, 7.5226e-05],\n        [2.9073e-01, 7.0923e-01, 4.0888e-05],\n        [2.0802e-01, 7.9192e-01, 5.5017e-05],\n        [2.4800e-01, 7.5196e-01, 3.9951e-05],\n        [1.8984e-01, 8.1011e-01, 4.8833e-05],\n        [1.8724e-02, 8.6996e-01, 1.1132e-01],\n        [2.9405e-02, 8.1814e-01, 1.5246e-01],\n        [1.4129e-02, 7.0651e-01, 2.7936e-01],\n        [8.6494e-03, 9.3024e-01, 6.1112e-02],\n        [1.0519e-02, 7.4552e-01, 2.4396e-01],\n        [1.8850e-02, 8.9228e-01, 8.8873e-02],\n        [3.5368e-02, 6.5689e-01, 3.0774e-01],\n        [1.4809e-02, 9.7984e-01, 5.3495e-03],\n        [1.2249e-02, 9.0829e-01, 7.9463e-02],\n        [2.4789e-02, 9.0786e-01, 6.7353e-02],\n        [6.3501e-03, 9.8403e-01, 9.6170e-03],\n        [2.8121e-02, 8.4741e-01, 1.2447e-01],\n        [4.5882e-03, 9.8151e-01, 1.3900e-02],\n        [1.6951e-02, 8.0762e-01, 1.7543e-01],\n        [2.8834e-02, 9.5285e-01, 1.8316e-02],\n        [1.8967e-02, 9.0284e-01, 7.8189e-02],\n        [3.2189e-02, 7.5809e-01, 2.0972e-01],\n        [1.3001e-02, 9.7682e-01, 1.0178e-02],\n        [4.9281e-03, 6.9082e-01, 3.0425e-01],\n        [1.0385e-02, 9.7383e-01, 1.5782e-02],\n        [2.0019e-02, 2.9141e-01, 6.8857e-01],\n        [1.4802e-02, 9.5010e-01, 3.5093e-02],\n        [5.7312e-03, 5.6017e-01, 4.3409e-01],\n        [1.3266e-02, 9.1984e-01, 6.6894e-02],\n        [1.4475e-02, 9.3608e-01, 4.9445e-02],\n        [1.6095e-02, 8.9575e-01, 8.8158e-02],\n        [8.6081e-03, 7.9613e-01, 1.9526e-01],\n        [7.8192e-03, 3.4226e-01, 6.4992e-01],\n        [1.8860e-02, 7.6657e-01, 2.1457e-01],\n        [1.2151e-02, 9.8301e-01, 4.8356e-03],\n        [9.2506e-03, 9.7556e-01, 1.5186e-02],\n        [8.9454e-03, 9.8289e-01, 8.1682e-03],\n        [1.4302e-02, 9.6505e-01, 2.0652e-02],\n        [6.6522e-03, 3.3750e-01, 6.5585e-01],\n        [3.7282e-02, 7.4791e-01, 2.1481e-01],\n        [6.3393e-02, 7.1911e-01, 2.1749e-01],\n        [1.7433e-02, 7.6642e-01, 2.1615e-01],\n        [5.2853e-03, 8.9545e-01, 9.9262e-02],\n        [3.4628e-02, 9.2814e-01, 3.7230e-02],\n        [1.2323e-02, 9.3497e-01, 5.2708e-02],\n        [1.3863e-02, 9.3073e-01, 5.5405e-02],\n        [2.2044e-02, 8.4163e-01, 1.3633e-01],\n        [1.1464e-02, 9.6175e-01, 2.6788e-02],\n        [1.1090e-02, 9.8315e-01, 5.7627e-03],\n        [1.6917e-02, 9.2280e-01, 6.0287e-02],\n        [3.0584e-02, 9.4445e-01, 2.4963e-02],\n        [2.4742e-02, 9.2695e-01, 4.8306e-02],\n        [1.6670e-02, 9.3174e-01, 5.1588e-02],\n        [1.7147e-02, 9.7796e-01, 4.8954e-03],\n        [1.9796e-02, 9.3493e-01, 4.5270e-02],\n        [2.6774e-04, 2.6186e-03, 9.9711e-01],\n        [2.6166e-03, 7.9669e-02, 9.1771e-01],\n        [4.1480e-04, 1.4210e-02, 9.8538e-01],\n        [2.2194e-03, 7.3972e-02, 9.2381e-01],\n        [4.1704e-04, 8.9348e-03, 9.9065e-01],\n        [1.4910e-04, 6.4334e-03, 9.9342e-01],\n        [1.2312e-02, 3.7591e-01, 6.1178e-01],\n        [5.5563e-04, 3.1725e-02, 9.6772e-01],\n        [6.8199e-04, 4.8360e-02, 9.5096e-01],\n        [3.3526e-04, 3.5550e-03, 9.9611e-01],\n        [4.1931e-03, 7.9243e-02, 9.1656e-01],\n        [1.4943e-03, 6.6569e-02, 9.3194e-01],\n        [8.1267e-04, 2.3729e-02, 9.7546e-01],\n        [1.5294e-03, 5.1235e-02, 9.4724e-01],\n        [5.3027e-04, 8.2495e-03, 9.9122e-01],\n        [9.7783e-04, 1.3356e-02, 9.8567e-01],\n        [3.0054e-03, 9.8123e-02, 8.9887e-01],\n        [6.5710e-04, 7.4897e-03, 9.9185e-01],\n        [3.9846e-05, 2.1124e-03, 9.9785e-01],\n        [3.9323e-03, 4.5444e-01, 5.4163e-01],\n        [4.4665e-04, 8.4709e-03, 9.9108e-01],\n        [3.3201e-03, 6.8516e-02, 9.2816e-01],\n        [1.3007e-04, 7.8380e-03, 9.9203e-01],\n        [4.0078e-03, 2.0034e-01, 7.9565e-01],\n        [1.3133e-03, 2.1271e-02, 9.7742e-01],\n        [1.7752e-03, 6.1821e-02, 9.3640e-01],\n        [5.9230e-03, 2.3858e-01, 7.5550e-01],\n        [8.8693e-03, 2.2798e-01, 7.6315e-01],\n        [5.5188e-04, 1.6382e-02, 9.8307e-01],\n        [3.1840e-03, 1.9375e-01, 8.0306e-01],\n        [4.1386e-04, 2.5778e-02, 9.7381e-01],\n        [1.9860e-03, 2.7296e-02, 9.7072e-01],\n        [3.9361e-04, 1.0500e-02, 9.8911e-01],\n        [8.7981e-03, 5.2023e-01, 4.7097e-01],\n        [5.0701e-03, 3.8222e-01, 6.1271e-01],\n        [1.4622e-04, 5.7101e-03, 9.9414e-01],\n        [7.9050e-04, 6.7263e-03, 9.9248e-01],\n        [4.1142e-03, 1.0349e-01, 8.9240e-01],\n        [1.0744e-02, 2.5809e-01, 7.3117e-01],\n        [1.1370e-03, 3.0425e-02, 9.6844e-01],\n        [3.2245e-04, 5.8004e-03, 9.9388e-01],\n        [8.4679e-04, 1.8951e-02, 9.8020e-01],\n        [2.6166e-03, 7.9669e-02, 9.1771e-01],\n        [3.5555e-04, 6.3124e-03, 9.9333e-01],\n        [3.2080e-04, 4.0090e-03, 9.9567e-01],\n        [6.3868e-04, 1.4580e-02, 9.8478e-01],\n        [1.7386e-03, 9.7665e-02, 9.0060e-01],\n        [2.1325e-03, 5.7823e-02, 9.4004e-01],\n        [1.6046e-03, 1.3323e-02, 9.8507e-01],\n        [7.4869e-03, 1.6261e-01, 8.2991e-01]], grad_fn=<SoftmaxBackward0>)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.2866e-01, 7.7130e-01, 4.2970e-05],\n        [1.2582e-01, 8.7412e-01, 6.1340e-05],\n        [2.0059e-01, 7.9935e-01, 5.2136e-05],\n        [1.7629e-01, 8.2365e-01, 6.1827e-05],\n        [2.6519e-01, 7.3477e-01, 4.1297e-05],\n        [2.8343e-01, 7.1651e-01, 5.4384e-05],\n        [2.6471e-01, 7.3524e-01, 5.6522e-05],\n        [2.1195e-01, 7.8800e-01, 4.7899e-05],\n        [1.4546e-01, 8.5447e-01, 7.1931e-05],\n        [1.4797e-01, 8.5198e-01, 4.9855e-05],\n        [2.3590e-01, 7.6406e-01, 3.9550e-05],\n        [2.3170e-01, 7.6825e-01, 5.1242e-05],\n        [1.3683e-01, 8.6312e-01, 5.2247e-05],\n        [1.9759e-01, 8.0236e-01, 5.0313e-05],\n        [2.5698e-01, 7.4299e-01, 3.0701e-05],\n        [3.4152e-01, 6.5844e-01, 4.1310e-05],\n        [2.9567e-01, 7.0429e-01, 4.4965e-05],\n        [2.3083e-01, 7.6912e-01, 5.0398e-05],\n        [2.2018e-01, 7.7977e-01, 4.6961e-05],\n        [2.9955e-01, 7.0040e-01, 4.5136e-05],\n        [1.6159e-01, 8.3836e-01, 4.9783e-05],\n        [2.8102e-01, 7.1893e-01, 5.5605e-05],\n        [3.2889e-01, 6.7107e-01, 3.6655e-05],\n        [1.6715e-01, 8.3275e-01, 9.8849e-05],\n        [2.1994e-01, 7.8000e-01, 5.8974e-05],\n        [1.1177e-01, 8.8816e-01, 6.5710e-05],\n        [2.0998e-01, 7.8995e-01, 7.1432e-05],\n        [2.1340e-01, 7.8656e-01, 4.4293e-05],\n        [1.9237e-01, 8.0758e-01, 4.4872e-05],\n        [1.8916e-01, 8.1078e-01, 5.9159e-05],\n        [1.5257e-01, 8.4737e-01, 6.2710e-05],\n        [1.6814e-01, 8.3180e-01, 6.5081e-05],\n        [3.2921e-01, 6.7076e-01, 3.1530e-05],\n        [3.2094e-01, 6.7903e-01, 3.2484e-05],\n        [1.4638e-01, 8.5356e-01, 5.9210e-05],\n        [1.7108e-01, 8.2888e-01, 4.8239e-05],\n        [1.8528e-01, 8.1468e-01, 3.9541e-05],\n        [2.7355e-01, 7.2642e-01, 3.6321e-05],\n        [1.7678e-01, 8.2315e-01, 6.3434e-05],\n        [2.0041e-01, 7.9954e-01, 4.7327e-05],\n        [2.4665e-01, 7.5331e-01, 4.8777e-05],\n        [3.4394e-02, 9.6546e-01, 1.4715e-04],\n        [2.3496e-01, 7.6499e-01, 5.4134e-05],\n        [2.3967e-01, 7.6023e-01, 9.9844e-05],\n        [2.9088e-01, 7.0906e-01, 6.4797e-05],\n        [1.3205e-01, 8.6788e-01, 7.5226e-05],\n        [2.9073e-01, 7.0923e-01, 4.0888e-05],\n        [2.0802e-01, 7.9192e-01, 5.5017e-05],\n        [2.4800e-01, 7.5196e-01, 3.9951e-05],\n        [1.8984e-01, 8.1011e-01, 4.8833e-05],\n        [1.8724e-02, 8.6996e-01, 1.1132e-01],\n        [2.9405e-02, 8.1814e-01, 1.5246e-01],\n        [1.4129e-02, 7.0651e-01, 2.7936e-01],\n        [8.6494e-03, 9.3024e-01, 6.1112e-02],\n        [1.0519e-02, 7.4552e-01, 2.4396e-01],\n        [1.8850e-02, 8.9228e-01, 8.8873e-02],\n        [3.5368e-02, 6.5689e-01, 3.0774e-01],\n        [1.4809e-02, 9.7984e-01, 5.3495e-03],\n        [1.2249e-02, 9.0829e-01, 7.9463e-02],\n        [2.4789e-02, 9.0786e-01, 6.7353e-02],\n        [6.3501e-03, 9.8403e-01, 9.6170e-03],\n        [2.8121e-02, 8.4741e-01, 1.2447e-01],\n        [4.5882e-03, 9.8151e-01, 1.3900e-02],\n        [1.6951e-02, 8.0762e-01, 1.7543e-01],\n        [2.8834e-02, 9.5285e-01, 1.8316e-02],\n        [1.8967e-02, 9.0284e-01, 7.8189e-02],\n        [3.2189e-02, 7.5809e-01, 2.0972e-01],\n        [1.3001e-02, 9.7682e-01, 1.0178e-02],\n        [4.9281e-03, 6.9082e-01, 3.0425e-01],\n        [1.0385e-02, 9.7383e-01, 1.5782e-02],\n        [2.0019e-02, 2.9141e-01, 6.8857e-01],\n        [1.4802e-02, 9.5010e-01, 3.5093e-02],\n        [5.7312e-03, 5.6018e-01, 4.3409e-01],\n        [1.3266e-02, 9.1984e-01, 6.6894e-02],\n        [1.4475e-02, 9.3608e-01, 4.9445e-02],\n        [1.6095e-02, 8.9575e-01, 8.8158e-02],\n        [8.6081e-03, 7.9613e-01, 1.9526e-01],\n        [7.8192e-03, 3.4226e-01, 6.4992e-01],\n        [1.8860e-02, 7.6657e-01, 2.1457e-01],\n        [1.2151e-02, 9.8301e-01, 4.8356e-03],\n        [9.2506e-03, 9.7556e-01, 1.5186e-02],\n        [8.9454e-03, 9.8289e-01, 8.1682e-03],\n        [1.4302e-02, 9.6505e-01, 2.0652e-02],\n        [6.6522e-03, 3.3750e-01, 6.5585e-01],\n        [3.7282e-02, 7.4791e-01, 2.1481e-01],\n        [6.3393e-02, 7.1911e-01, 2.1749e-01],\n        [1.7433e-02, 7.6642e-01, 2.1615e-01],\n        [5.2853e-03, 8.9545e-01, 9.9262e-02],\n        [3.4628e-02, 9.2814e-01, 3.7230e-02],\n        [1.2323e-02, 9.3497e-01, 5.2708e-02],\n        [1.3863e-02, 9.3073e-01, 5.5405e-02],\n        [2.2044e-02, 8.4163e-01, 1.3633e-01],\n        [1.1464e-02, 9.6175e-01, 2.6788e-02],\n        [1.1090e-02, 9.8315e-01, 5.7627e-03],\n        [1.6917e-02, 9.2280e-01, 6.0287e-02],\n        [3.0584e-02, 9.4445e-01, 2.4963e-02],\n        [2.4742e-02, 9.2695e-01, 4.8306e-02],\n        [1.6670e-02, 9.3174e-01, 5.1588e-02],\n        [1.7147e-02, 9.7796e-01, 4.8954e-03],\n        [1.9796e-02, 9.3493e-01, 4.5270e-02],\n        [2.6774e-04, 2.6186e-03, 9.9711e-01],\n        [2.6166e-03, 7.9669e-02, 9.1771e-01],\n        [4.1480e-04, 1.4210e-02, 9.8538e-01],\n        [2.2194e-03, 7.3972e-02, 9.2381e-01],\n        [4.1704e-04, 8.9348e-03, 9.9065e-01],\n        [1.4910e-04, 6.4334e-03, 9.9342e-01],\n        [1.2312e-02, 3.7591e-01, 6.1178e-01],\n        [5.5563e-04, 3.1725e-02, 9.6772e-01],\n        [6.8199e-04, 4.8360e-02, 9.5096e-01],\n        [3.3526e-04, 3.5550e-03, 9.9611e-01],\n        [4.1931e-03, 7.9243e-02, 9.1656e-01],\n        [1.4943e-03, 6.6569e-02, 9.3194e-01],\n        [8.1267e-04, 2.3729e-02, 9.7546e-01],\n        [1.5294e-03, 5.1235e-02, 9.4724e-01],\n        [5.3027e-04, 8.2495e-03, 9.9122e-01],\n        [9.7783e-04, 1.3356e-02, 9.8567e-01],\n        [3.0054e-03, 9.8123e-02, 8.9887e-01],\n        [6.5710e-04, 7.4897e-03, 9.9185e-01],\n        [3.9846e-05, 2.1124e-03, 9.9785e-01],\n        [3.9323e-03, 4.5444e-01, 5.4163e-01],\n        [4.4665e-04, 8.4709e-03, 9.9108e-01],\n        [3.3201e-03, 6.8516e-02, 9.2816e-01],\n        [1.3007e-04, 7.8380e-03, 9.9203e-01],\n        [4.0078e-03, 2.0034e-01, 7.9565e-01],\n        [1.3133e-03, 2.1271e-02, 9.7742e-01],\n        [1.7752e-03, 6.1821e-02, 9.3640e-01],\n        [5.9230e-03, 2.3858e-01, 7.5550e-01],\n        [8.8693e-03, 2.2798e-01, 7.6315e-01],\n        [5.5188e-04, 1.6382e-02, 9.8307e-01],\n        [3.1840e-03, 1.9375e-01, 8.0306e-01],\n        [4.1386e-04, 2.5778e-02, 9.7381e-01],\n        [1.9860e-03, 2.7296e-02, 9.7072e-01],\n        [3.9361e-04, 1.0500e-02, 9.8911e-01],\n        [8.7981e-03, 5.2023e-01, 4.7097e-01],\n        [5.0701e-03, 3.8222e-01, 6.1271e-01],\n        [1.4622e-04, 5.7101e-03, 9.9414e-01],\n        [7.9050e-04, 6.7263e-03, 9.9248e-01],\n        [4.1142e-03, 1.0349e-01, 8.9240e-01],\n        [1.0744e-02, 2.5809e-01, 7.3117e-01],\n        [1.1370e-03, 3.0425e-02, 9.6844e-01],\n        [3.2245e-04, 5.8004e-03, 9.9388e-01],\n        [8.4679e-04, 1.8951e-02, 9.8020e-01],\n        [2.6166e-03, 7.9669e-02, 9.1771e-01],\n        [3.5555e-04, 6.3124e-03, 9.9333e-01],\n        [3.2080e-04, 4.0090e-03, 9.9567e-01],\n        [6.3868e-04, 1.4580e-02, 9.8478e-01],\n        [1.7386e-03, 9.7665e-02, 9.0060e-01],\n        [2.1325e-03, 5.7823e-02, 9.4004e-01],\n        [1.6046e-03, 1.3323e-02, 9.8507e-01],\n        [7.4869e-03, 1.6261e-01, 8.2991e-01]], grad_fn=<SoftmaxBackward0>)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_model(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}