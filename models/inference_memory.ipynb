{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "from actuallysparse import converter\n",
    "from warnings import filterwarnings\n",
    "from torch.autograd.profiler import profile\n",
    "\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_loader_very_pruned = lambda: torch.load(\"../.weights/full/very_pruned\", map_location=torch.device('cpu')).eval()\n",
    "model_loader_pruned = lambda: torch.load(\"../.weights/full/pruned\", map_location=torch.device('cpu')).eval()\n",
    "model_loader_pretrained = lambda: torch.load(\"../.weights/full/pretrained\", map_location=torch.device('cpu')).eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): ReLU(inplace=True)\n    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (10): ReLU(inplace=True)\n    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (13): ReLU(inplace=True)\n    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (17): ReLU(inplace=True)\n    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (20): ReLU(inplace=True)\n    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (24): ReLU(inplace=True)\n    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (27): ReLU(inplace=True)\n    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (classifier): Sequential(\n    (0): SparseLayer(in_features=512, out_features=4096, bias=True, csr_mode=False, k=0.05)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): SparseLayer(in_features=4096, out_features=4096, bias=True, csr_mode=False, k=0.05)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): SparseLayer(in_features=4096, out_features=10, bias=True, csr_mode=False, k=0.05)\n  )\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = torch.ones(1,3,244,244)\n",
    "dense = model_loader_very_pruned().to(device).eval()\n",
    "coo = converter.convert_model(model_loader_very_pruned(), torch.nn.Linear, \"coo\").to(device)\n",
    "coo.train(False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::conv2d         0.06%      85.000us        82.85%     111.749ms      13.969ms      33.46 Mb           0 b             8  \n",
      "                aten::convolution         0.18%     245.000us        82.78%     111.664ms      13.958ms      33.46 Mb           0 b             8  \n",
      "               aten::_convolution         0.11%     148.000us        82.60%     111.419ms      13.927ms      33.46 Mb           0 b             8  \n",
      "         aten::mkldnn_convolution        82.31%     111.022ms        82.49%     111.271ms      13.909ms      33.46 Mb           0 b             8  \n",
      "                 aten::max_pool2d         0.03%      46.000us         7.24%       9.768ms       1.954ms      20.59 Mb           0 b             5  \n",
      "    aten::max_pool2d_with_indices         7.21%       9.722ms         7.21%       9.722ms       1.944ms      20.59 Mb      20.59 Mb             5  \n",
      "                 aten::batch_norm         0.03%      43.000us         4.50%       6.064ms     758.000us      33.46 Mb           0 b             8  \n",
      "     aten::_batch_norm_impl_index         0.07%     100.000us         4.46%       6.021ms     752.625us      33.46 Mb           0 b             8  \n",
      "          aten::native_batch_norm         4.23%       5.711ms         4.37%       5.895ms     736.875us      33.46 Mb     -19.25 Kb             8  \n",
      "                     aten::linear         0.03%      43.000us         2.99%       4.035ms       1.345ms      32.04 Kb           0 b             3  \n",
      "                      aten::addmm         2.86%       3.852ms         2.90%       3.906ms       1.302ms      32.04 Kb      32.04 Kb             3  \n",
      "                      aten::relu_         0.14%     185.000us         2.25%       3.035ms     303.500us           0 b           0 b            10  \n",
      "                 aten::clamp_min_         2.11%       2.850ms         2.11%       2.850ms     285.000us           0 b           0 b            10  \n",
      "                      aten::empty         0.30%     402.000us         0.30%     402.000us       6.281us      66.95 Mb      66.95 Mb            64  \n",
      "        aten::adaptive_avg_pool2d         0.01%      16.000us         0.15%     203.000us     203.000us       2.00 Kb           0 b             1  \n",
      "                       aten::mean         0.03%      46.000us         0.14%     187.000us     187.000us       2.00 Kb       1.99 Kb             1  \n",
      "                 aten::empty_like         0.02%      31.000us         0.11%     150.000us      18.750us      33.46 Mb           0 b             8  \n",
      "                          aten::t         0.04%      48.000us         0.06%      86.000us      28.667us           0 b           0 b             3  \n",
      "                        aten::sum         0.06%      77.000us         0.06%      81.000us      81.000us           0 b           0 b             1  \n",
      "                       aten::div_         0.03%      34.000us         0.04%      60.000us      60.000us           8 b           4 b             1  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 134.889ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with profile(profile_memory=True, record_shapes=True) as prof:\n",
    "        dense(dummy_input)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                              Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "--------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                      aten::conv2d         0.04%      50.000us        80.13%     110.706ms      13.838ms      33.46 Mb           0 b             8  \n",
      "                                 aten::convolution         0.13%     181.000us        80.10%     110.656ms      13.832ms      33.46 Mb           0 b             8  \n",
      "                                aten::_convolution         0.07%      96.000us        79.96%     110.475ms      13.809ms      33.46 Mb           0 b             8  \n",
      "                          aten::mkldnn_convolution        79.72%     110.144ms        79.90%     110.379ms      13.797ms      33.46 Mb           0 b             8  \n",
      "                                  aten::max_pool2d         0.03%      38.000us         8.06%      11.135ms       2.227ms      20.59 Mb           0 b             5  \n",
      "                     aten::max_pool2d_with_indices         8.03%      11.097ms         8.03%      11.097ms       2.219ms      20.59 Mb      20.59 Mb             5  \n",
      "                                  aten::batch_norm         0.03%      35.000us         4.28%       5.909ms     738.625us      33.46 Mb           0 b             8  \n",
      "                                       SPARSE PASS         0.16%     219.000us         4.26%       5.883ms       1.961ms      32.03 Kb     -32.65 Kb             3  \n",
      "                      aten::_batch_norm_impl_index         0.06%      87.000us         4.25%       5.874ms     734.250us      33.46 Mb           0 b             8  \n",
      "                           aten::native_batch_norm         4.05%       5.601ms         4.17%       5.765ms     720.625us      33.46 Mb     -20.50 Kb             8  \n",
      "                                  aten::_sparse_mm         0.02%      31.000us         4.00%       5.520ms       1.840ms      32.08 Kb     -32.00 Kb             3  \n",
      "                               aten::_sparse_addmm         0.03%      48.000us         3.95%       5.458ms       1.819ms      32.04 Kb           0 b             3  \n",
      "                                       aten::addmm         3.91%       5.400ms         3.92%       5.410ms       1.803ms      32.04 Kb          40 b             3  \n",
      "                                       aten::relu_         0.11%     155.000us         2.50%       3.457ms     345.700us           0 b           0 b            10  \n",
      "                                  aten::clamp_min_         2.39%       3.302ms         2.39%       3.302ms     330.200us           0 b           0 b            10  \n",
      "                           aten::sparse_coo_tensor         0.03%      44.000us         0.63%     864.000us     288.000us           0 b        -192 b             3  \n",
      "                                         aten::min         0.28%     388.000us         0.30%     416.000us     138.667us          96 b          96 b             3  \n",
      "                                       aten::empty         0.29%     397.000us         0.29%     397.000us       4.841us      66.98 Mb      66.98 Mb            82  \n",
      "                                         aten::max         0.22%     299.000us         0.24%     325.000us     108.333us          96 b          96 b             3  \n",
      "                         aten::adaptive_avg_pool2d         0.00%       5.000us         0.11%     157.000us     157.000us       2.00 Kb           0 b             1  \n",
      "--------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 138.155ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with profile(profile_memory=True, record_shapes=True) as prof:\n",
    "        coo(dummy_input)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
