{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dccdf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torchvision\n",
    "import actuallysparse.converter as converter\n",
    "import actuallysparse.layers as layers\n",
    "import pretrained\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa34676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pruning_device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37b07d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ładowanie modeli\n",
    "pretrained_model = torch.load(\".weights/full/pretrained\", map_location=torch.device('cpu'))\n",
    "extra_trained = torch.load(\".weights/full/extra_trained\", map_location=torch.device('cpu'))\n",
    "pruned_model = torch.load(\".weights/full/pruned\", map_location=torch.device('cpu'))\n",
    "very_pruned_model = torch.load(\".weights/full/very_pruned\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab428097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataloader_train, dataloader_test = pretrained.load_cifar10_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99eebb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(model, dataset=\"train\"):\n",
    "    dataloader = dataloader_train if dataset == \"train\" else dataloader_test\n",
    "    with torch.no_grad():\n",
    "        model.to(training_device)\n",
    "        correct = 0\n",
    "        all_so_far = 0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(training_device), labels.to(training_device)\n",
    "            pred = torch.argmax(model(inputs), dim=1)\n",
    "\n",
    "            all_so_far += labels.size().numel()\n",
    "            correct += torch.sum(pred.eq(labels))\n",
    "    return correct/all_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def convolutional_pass(model):\n",
    "    passed_data = []\n",
    "    for data in dataloader_train:\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = data\n",
    "            inputs_for_sparse = model.features(inputs)\n",
    "            inputs_for_sparse = model.avgpool(inputs_for_sparse)\n",
    "            inputs_for_sparse = inputs_for_sparse.view(inputs_for_sparse.size(0), -1)\n",
    "            *conv_data, = inputs_for_sparse, labels\n",
    "            passed_data.append(conv_data)\n",
    "    return passed_data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def train_prune_loop(model, data, optimizer, criterion,max_epochs = 2000, epochs_to_prune = 15):\n",
    "    in_classifier_features = model.classifier[0].in_features\n",
    "    dummy_input = torch.ones(in_classifier_features)\n",
    "    model.train()\n",
    "    for epoch in range(max_epochs):\n",
    "        if epoch % epochs_to_prune == 0:\n",
    "            layers.prune_model(model.classifier, dummy_input)\n",
    "            print(\"Pruned!\")\n",
    "        for entry in data:\n",
    "            inputs_for_sparse, labels = entry\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model.classifier(inputs_for_sparse)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch:{epoch}, loss:{loss}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56f12ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model_coo = copy.deepcopy(pruned_model)\n",
    "pruned_model_coo.classifier = converter.convert_model(pruned_model_coo.classifier, Linear, 'coo')\n",
    "for child in pruned_model_coo.classifier.children():\n",
    "    if type(child) is layers.SparseLayer:\n",
    "        child.set_k(0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(pruned_model_coo.classifier.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "passed_data = convolutional_pass(pruned_model_coo)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned!\n",
      "Epoch:0, loss:0.006521960254758596\n",
      "Epoch:1, loss:0.004795870278030634\n",
      "Epoch:2, loss:0.006124990060925484\n",
      "Epoch:3, loss:0.008161676116287708\n",
      "Epoch:4, loss:0.006097306497395039\n",
      "Epoch:5, loss:0.01150859147310257\n",
      "Epoch:6, loss:0.008162113837897778\n",
      "Epoch:7, loss:0.0070147328078746796\n",
      "Epoch:8, loss:0.0071838791482150555\n",
      "Epoch:9, loss:0.005080321803689003\n",
      "Epoch:10, loss:0.004910708405077457\n",
      "Epoch:11, loss:0.006445376668125391\n",
      "Epoch:12, loss:0.008207106962800026\n",
      "Epoch:13, loss:0.01086659636348486\n",
      "Epoch:14, loss:0.010599001310765743\n",
      "Pruned!\n",
      "Epoch:15, loss:0.015457019209861755\n",
      "Epoch:16, loss:0.004612844903022051\n",
      "Epoch:17, loss:0.008892080746591091\n",
      "Epoch:18, loss:0.0054727233946323395\n",
      "Epoch:19, loss:0.00818454660475254\n",
      "Epoch:20, loss:0.010733014903962612\n",
      "Epoch:21, loss:0.008907218463718891\n",
      "Epoch:22, loss:0.009959240444004536\n",
      "Epoch:23, loss:0.009082750417292118\n",
      "Epoch:24, loss:0.0062526194378733635\n",
      "Epoch:25, loss:0.00681970315054059\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[41], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain_prune_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpruned_model_coo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpassed_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m59\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[39], line 14\u001B[0m, in \u001B[0;36mtrain_prune_loop\u001B[1;34m(model, data, optimizer, criterion, max_epochs, epochs_to_prune)\u001B[0m\n\u001B[0;32m     12\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mclassifier(inputs_for_sparse)\n\u001B[0;32m     13\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n\u001B[1;32m---> 14\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, loss:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\PracaInżynierska\\lib\\site-packages\\torch\\_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    486\u001B[0m     )\n\u001B[1;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PracaInżynierska\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    192\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    194\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 197\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_prune_loop(pruned_model_coo, passed_data, optimizer, criterion, max_epochs=59)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pruned_model_coo.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.8237)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_accuracy(pruned_model_coo, dataset=\"test\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
